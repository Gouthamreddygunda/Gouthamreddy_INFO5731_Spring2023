{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gouthamreddygunda/Gouthamreddy_INFO5731_Spring2023/blob/main/In_class_exercise_02_02072023_goutham_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hznInHvjq6gR"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xptphq2q6gU"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6rZZxijq6gU"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3B3QaCaq6gV"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "I choose the movies as the interesting topic and to choose a good movie or to grade a good movie we see lot of opinions and understanding the particular features.\n",
        "I am collecting the movie ratings. I have did collected review and rating.\n",
        "The Beautifulsoap library is utilized for data extraction.\n",
        "Data is extracted using a class, stored in a list, and then transformed into a dataframe.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwxZlodbq6gW"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ3x7wlAq6gW",
        "outputId": "15d21ef0-a8cf-47e4-a17a-6df7e10edb39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.imdb.com/title/tt14826022/reviews', 'https://www.imdb.com/title/tt10640346/reviews', 'https://www.imdb.com/title/tt9114286/reviews', 'https://www.imdb.com/title/tt1630029/reviews', 'https://www.imdb.com/title/tt9764362/reviews', 'https://www.imdb.com/title/tt9686790/reviews', 'https://www.imdb.com/title/tt11813216/reviews', 'https://www.imdb.com/title/tt6710474/reviews', 'https://www.imdb.com/title/tt15679400/reviews', 'https://www.imdb.com/title/tt8760708/reviews', 'https://www.imdb.com/title/tt10365998/reviews', 'https://www.imdb.com/title/tt15486810/reviews', 'https://www.imdb.com/title/tt12844910/reviews', 'https://www.imdb.com/title/tt3915174/reviews', 'https://www.imdb.com/title/tt5884796/reviews', 'https://www.imdb.com/title/tt14444726/reviews', 'https://www.imdb.com/title/tt14208870/reviews', 'https://www.imdb.com/title/tt11564570/reviews', 'https://www.imdb.com/title/tt3704428/reviews', 'https://www.imdb.com/title/tt13833688/reviews', 'https://www.imdb.com/title/tt1016150/reviews', 'https://www.imdb.com/title/tt7322224/reviews', 'https://www.imdb.com/title/tt7405458/reviews', 'https://www.imdb.com/title/tt14138650/reviews', 'https://www.imdb.com/title/tt13560574/reviews', 'https://www.imdb.com/title/tt18079362/reviews', 'https://www.imdb.com/title/tt15255288/reviews', 'https://www.imdb.com/title/tt19770238/reviews', 'https://www.imdb.com/title/tt1745960/reviews', 'https://www.imdb.com/title/tt12593682/reviews', 'https://www.imdb.com/title/tt0107048/reviews', 'https://www.imdb.com/title/tt14209916/reviews', 'https://www.imdb.com/title/tt9737876/reviews', 'https://www.imdb.com/title/tt10954600/reviews', 'https://www.imdb.com/title/tt13539646/reviews', 'https://www.imdb.com/title/tt8129806/reviews', 'https://www.imdb.com/title/tt13669038/reviews', 'https://www.imdb.com/title/tt10151854/reviews', 'https://www.imdb.com/title/tt8946378/reviews', 'https://www.imdb.com/title/tt6718170/reviews', 'https://www.imdb.com/title/tt0499549/reviews', 'https://www.imdb.com/title/tt8041270/reviews', 'https://www.imdb.com/title/tt1877830/reviews', 'https://www.imdb.com/title/tt3427252/reviews', 'https://www.imdb.com/title/tt10304142/reviews', 'https://www.imdb.com/title/tt15600222/reviews', 'https://www.imdb.com/title/tt9411972/reviews', 'https://www.imdb.com/title/tt10855768/reviews', 'https://www.imdb.com/title/tt19623240/reviews', 'https://www.imdb.com/title/tt11976532/reviews']\n",
            "https://www.imdb.com/title/tt14826022/reviews\n",
            "https://www.imdb.com/title/tt10640346/reviews\n",
            "vote : 25 review list:25\n",
            "rating1:25\n",
            "vote : 50 review list:50\n",
            "rating1:50\n",
            "vote : 75 review list:75\n",
            "rating1:75\n",
            "vote : 100 review list:100\n",
            "rating1:100\n",
            "vote : 125 review list:125\n",
            "rating1:125\n",
            "vote : 150 review list:150\n",
            "rating1:150\n",
            "vote : 175 review list:175\n",
            "rating1:175\n",
            "vote : 200 review list:200\n",
            "rating1:200\n",
            "vote : 225 review list:225\n",
            "rating1:225\n",
            "vote : 250 review list:250\n",
            "rating1:250\n",
            "vote : 275 review list:275\n",
            "rating1:275\n",
            "vote : 300 review list:300\n",
            "rating1:300\n",
            "vote : 325 review list:325\n",
            "rating1:325\n",
            "vote : 350 review list:350\n",
            "rating1:350\n",
            "vote : 375 review list:375\n",
            "rating1:375\n",
            "vote : 400 review list:400\n",
            "rating1:400\n",
            "vote : 425 review list:425\n",
            "rating1:425\n",
            "vote : 450 review list:450\n",
            "rating1:450\n",
            "vote : 475 review list:475\n",
            "rating1:475\n",
            "vote : 500 review list:500\n",
            "rating1:500\n",
            "vote : 525 review list:525\n",
            "rating1:525\n",
            "vote : 550 review list:550\n",
            "rating1:550\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "url_title_g = 'https://www.imdb.com/search/title/?title_type=feature' \n",
        "request = requests.get(url_title_g)\n",
        "url_dt_g = BeautifulSoup(request.text, 'lxml') \n",
        "url_tg_g = url_dt_g.find_all('a', attrs={'class': None})\n",
        "url_tg_dt_g = [tag.attrs['href'] for tag in url_tg_g \n",
        "              if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]\n",
        "url_tg_dt_g = list(dict.fromkeys(url_tg_dt_g)) \n",
        "url_link_g = [\"https://www.imdb.com\" + tag + 'reviews' for tag in url_tg_dt_g]\n",
        "print(url_link_g)\n",
        "print(url_link_g[0])\n",
        "print(url_link_g[1])\n",
        "\n",
        "def getindex(a):\n",
        "    min_position = a.index(min(a))\n",
        "    max_position = a.index(max(a))\n",
        "    return min_position,max_position\n",
        "\n",
        "com = []\n",
        "votes1 = []\n",
        "vt1=[]\n",
        "Uid=[]\n",
        "cine=[]\n",
        "review_nt=[]\n",
        "for i in range(0,50):\n",
        "    url_dt_g = BeautifulSoup(requests.get(url_link_g[i]).text, 'html.parser')\n",
        "    voting = [tag.previous_element for tag in \n",
        "                           url_dt_g.find_all('span', attrs={'class': 'point-scale'})]\n",
        "    if len(voting) > 0:  \n",
        "        n_index, p_index = getindex(list(map(int, voting)))\n",
        "        review_lst = url_dt_g.find_all('a', attrs={'class':'title'})\n",
        "        revw = [\"https://www.imdb.com\" + review['href'] for review in review_lst]\n",
        "    else:\n",
        "        print(None)\n",
        "\n",
        "\n",
        "\n",
        "    for j in revw:\n",
        "        txt=BeautifulSoup(requests.get(j).text, 'html.parser').find('div', attrs={'class': 'text show-more__control'}).get_text()\n",
        "        rating=BeautifulSoup(requests.get(j).text, 'html.parser').find('div', attrs={'class': 'lister-item-content'}).get_text()\n",
        "        movieusers=(BeautifulSoup(requests.get(j).text, 'html.parser').find('title').get_text())\n",
        "        descr=(BeautifulSoup(requests.get(j).text, 'html.parser').find('a', attrs={'class': 'title'}).get_text())\n",
        "        len_rating1=len(vt1)\n",
        "        if(txt == ''):\n",
        "            com.append('No Review')\n",
        "        else:\n",
        "            com.append(txt)\n",
        "        votes1.append(rating)\n",
        "\n",
        "        Uid.append(movieusers.split(\"'s\")[0])\n",
        "        cine.append(movieusers.split('Review of')[1])\n",
        "        review_nt.append(descr)\n",
        "  \n",
        "    print('vote : '+str(len(votes1))+' review list:'+str(len(com)))\n",
        "    if(len_rating1==0):\n",
        "        g=0\n",
        "    else:\n",
        "        g=len_rating1\n",
        "    for j in range(g,len(votes1)):\n",
        "        vt1.append(votes1[j].split('/10')[0].split('\\n')[len(votes1[j].split('/10')[0].split('\\n'))-1])\n",
        "    print('rating1:'+str(len(vt1)))\n",
        "\n",
        "data_review = {\n",
        "        \"Cinema name\" : cine,\n",
        "        \"User Name\" : Uid,\n",
        "        \"Review_Note\" : review_nt,\n",
        "        'Detail Reviews': com,\n",
        "        'Rating': vt1,\n",
        "        \n",
        "        }\n",
        "df = pd.DataFrame(data_review)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_ccq6-nq6gX"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMLWyiM7q6gX"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import json as j\n",
        "import urllib.request as request\n",
        "from bs4 import BeautifulSoup as beauty\n",
        "\n",
        "with request.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as fileread:\n",
        "    p_g = fileread.read()\n",
        "    s_g = beauty(p_g)\n",
        "    print(s_g.p_g.text)\n",
        "    with open('output.txt', 'w') as filewrite:\n",
        "        j.dump(s_g.p_g.text, filewrite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppVhPAr9q6gY"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_3BswjUq6gY"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n",
        "import json as j\n",
        "import urllib.request as request\n",
        "from bs4 import BeautifulSoup as beauty\n",
        "\n",
        "with request.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as fileread:\n",
        "    p_g = fileread.read()\n",
        "    s_g = beauty(p_g)\n",
        "    print(s_g.p_g.text)\n",
        "    with open('output.txt', 'w') as filewrite:\n",
        "        j.dump(s_g.p_g.text, filewrite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ktWl34BRmqa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}